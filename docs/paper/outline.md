# Abstract


# 1. Introduction


## 1.1 Background
Business Challenge:
Why Do Banks Find Business Process Compliance So Challenging? An Australian  Case Study: https://arxiv.org/pdf/2203.14904


Machine Learning Developer Challenge:
- Methodology space is evolving, day by day. 
- The size of domain specific tasks is huge and versatile. 
- Time available to adoption is limited.
- Agent vs. Non-agent approach: which is more suitable for the task?



## 1.2 Motivation
- Examine whether agent or non-agent approach is more suitable for the task.
- Reduce time required to develop an AI solution for a specific task
- Understand which model is best for what task
- 



# 2. Review of Existing Literature

## 2.1 Existing Approaches to Developiing Solution to Generative AI


### 2.1.1 Prompt Optimisation


Survey of Automatic Prompt Optimisation Techniques:https://arxiv.org/pdf/2502.16923



### 2.1.2 Model Selection (Open-sourced vs. Proprietory, Large Model vs. Small Model)
- Various choice of models are available.


### 2.1.3 Test Time Scaling Strategy
- Multi-Agent Design - Optimising Agents with Better Prompt and Topologies
- 

### 2.1.4 Model Configuration Tuning
Temperature
Top-P
Top-K


- Multi-Agent Design - Optimising Agents with Better Prompt and Topologies


## 2.2 Heuristic Search, Meta-Heuristic Optimisation and Hyper-Heuristic Optimisation

Overview of Hyper-Heuristic Algorithms
Hyper-heuristic algorithms are high-level search techniques designed to automate the selection, generation, and adaptation of heuristics for solving complex optimization problems. They operate on a search space of heuristics rather than directly on the solution space of the problem, making them more generalizable and reusable across different problem domains. This section provides a comprehensive overview of hyper-heuristic algorithms, including their categories, examples, mechanisms of operation, and their pros and cons.

Categories of Hyper-Heuristic Algorithms
Hyper-heuristic algorithms can be broadly categorized into two main types: selection hyper-heuristics and generation hyper-heuristics. These categories are based on how the algorithms interact with low-level heuristics and the problem-solving process.

1. Selection Hyper-Heuristics
Selection hyper-heuristics focus on choosing the most appropriate low-level heuristic from a predefined set to apply at each stage of the search process. These algorithms do not modify or generate new heuristics but instead select and sequence existing ones to solve the problem effectively.

Examples of Selection Hyper-Heuristics:
Choice Function Hyper-Heuristics: These use a scoring mechanism to select heuristics based on their historical performance. For instance, the choice function hyper-heuristic evaluates the quality of solutions generated by each heuristic and selects the one with the highest score (Özçağdavul, 2024).
Reinforcement Learning Hyper-Heuristics: These employ reinforcement learning to adaptively select heuristics based on the state of the search process. For example, in multi-objective optimization, reinforcement learning hyper-heuristics can dynamically prioritize operators to balance convergence and diversity (Heise & Mostaghim, 2023).
Simple Random Hyper-Heuristics: These randomly select heuristics from the pool without any adaptive mechanism. While simple, they can be effective for certain problem domains (Özçağdavul, 2024).
Mechanism of Operation:
Selection hyper-heuristics typically consist of two main components:

Heuristic Selection: This component decides which low-level heuristic to apply at each step. The selection can be based on performance metrics, reinforcement learning, or random choice.
Move Acceptance: This component determines whether to accept or reject the solution generated by the selected heuristic. Common acceptance mechanisms include "Only Improvement" (accepting only better solutions) and "Great Deluge" (accepting worse solutions to avoid stagnation) (Özçağdavul, 2024) (Kafafy et al., 2022).
Pros and Cons:
Pros: Selection hyper-heuristics are easy to implement and can generalize well across different problem domains. They are particularly effective when the low-level heuristics are well-suited for the problem.
Cons: Their performance heavily depends on the quality of the low-level heuristics in the pool. Poorly designed heuristics can lead to suboptimal solutions.
2. Generation Hyper-Heuristics
Generation hyper-heuristics go beyond selecting existing heuristics by generating new heuristics or modifying existing ones during the search process. These algorithms are more flexible and can adapt to the problem's requirements dynamically.

Examples of Generation Hyper-Heuristics:
Genetic Algorithm-Based Hyper-Heuristics: These use genetic algorithms to evolve new heuristics by combining and modifying existing ones. For example, a self-learning hyper-heuristic based on genetic algorithms has been successfully applied to logistics scheduling problems in cruise ship manufacturing (Li et al., 2024).
Neuroevolution-Based Hyper-Heuristics: These use neural networks to generate heuristics. The neural network is trained on problem instances and then used to control the application of low-level operators during optimization (Arza et al., 2020).
Memetic Algorithm-Based Hyper-Heuristics: These combine genetic algorithms with local search techniques to generate and adapt heuristics. Multi-meme memetic algorithms, for instance, integrate multiple heuristics and parameters to solve complex optimization problems (Özçağdavul, 2024).
Mechanism of Operation:
Generation hyper-heuristics typically involve the following steps:

Heuristic Generation: New heuristics are created by combining or modifying existing ones. This can involve genetic operators like crossover and mutation or neural network-based generation.
Heuristic Adaptation: The generated heuristics are adapted based on their performance during the search process. This adaptation can involve feedback mechanisms or learning strategies.
Solution Improvement: The generated heuristics are applied to improve the solution iteratively.
Pros and Cons:
Pros: Generation hyper-heuristics are highly flexible and can adapt to changing problem conditions. They are particularly useful for solving dynamic or multi-objective optimization problems.
Cons: These algorithms can be computationally expensive due to the overhead of generating and adapting heuristics. They also require careful design to ensure the generated heuristics are effective.
Specialized Hyper-Heuristic Approaches
In addition to the two main categories, several specialized hyper-heuristic approaches have been developed to address specific problem domains or requirements.

1. Multi-Level Hyper-Heuristics
Multi-level hyper-heuristics extend the basic framework by introducing additional levels of abstraction. These algorithms use high-level strategies to select and combine lower-level hyper-heuristics, further enhancing their generality and adaptability.

Example:
Roulette Wheel Selection Hyper-Heuristics: These use a roulette wheel mechanism to select the most promising hyper-heuristic based on its historical performance. This approach has been shown to outperform other methods on benchmark datasets (Kafafy et al., 2022).
Mechanism of Operation:
High-Level Strategy: Selects the appropriate hyper-heuristic to apply based on performance metrics.
Low-Level Heuristics: Solves the problem using the selected hyper-heuristic.
Performance Evaluation: Monitors the performance of each hyper-heuristic and updates the selection mechanism accordingly.
Pros and Cons:
Pros: Multi-level hyper-heuristics can handle complex optimization problems by leveraging the strengths of multiple hyper-heuristics.
Cons: The added complexity can lead to increased computational overhead and require careful tuning of the selection mechanism.
2. Parallel Hyper-Heuristics
Parallel hyper-heuristics leverage parallel computing to improve the efficiency and scalability of the search process. These algorithms are particularly useful for solving large-scale optimization problems.

Example:
Distributed Hyper-Heuristics: These algorithms distribute the search process across multiple processors or nodes, allowing for parallel execution of different heuristics. This approach has been applied to solve scheduling problems in cruise ship manufacturing (Li et al., 2024).
Mechanism of Operation:
Parallel Execution: Multiple heuristics are executed in parallel across different processors or nodes.
Solution Sharing: Solutions are shared between nodes to ensure global progress and avoid redundant work.
Load Balancing: The algorithm dynamically balances the workload to ensure efficient utilization of resources.
Pros and Cons:
Pros: Parallel hyper-heuristics can significantly reduce the computational time for large-scale problems. They are also scalable and can handle distributed optimization tasks effectively.
Cons: The complexity of implementing parallel hyper-heuristics can be high, and they may require specialized hardware or software infrastructure.
3. Online Learning Hyper-Heuristics
Online learning hyper-heuristics incorporate machine learning techniques to dynamically adapt the selection and generation of heuristics during the search process. These algorithms are particularly effective for dynamic optimization problems where the problem conditions change over time.

Example:
Reinforcement Learning Hyper-Heuristics: These algorithms use reinforcement learning to adapt the selection of heuristics based on the current state of the search process. For instance, HHX-A, a hyper-heuristic that alternately selects all operators or a single operator, has been shown to perform well on multi-objective optimization problems (Heise & Mostaghim, 2023).
Mechanism of Operation:
State Representation: The current state of the search process is represented using features or metrics.
Action Selection: The algorithm selects the most promising heuristic based on the current state and historical performance.
Reward Calculation: The algorithm receives a reward or penalty based on the quality of the solution generated.
Policy Update: The selection policy is updated to reflect the new information and improve future decisions.
Pros and Cons:
Pros: Online learning hyper-heuristics can adapt to changing problem conditions and improve their performance over time. They are particularly useful for dynamic and multi-objective optimization problems.
Cons: The learning process can be computationally expensive, and the algorithm may require a large amount of training data to achieve good performance.
Table Comparing Key Hyper-Heuristic Categories
Category	Mechanism/Examples	Pros and Cons
Selection Hyper-Heuristics	Uses choice functions, reinforcement learning, or random selection to choose heuristics.	Easy to implement, generalizable; performance depends on heuristic pool quality.
Generation Hyper-Heuristics	Generates new heuristics using genetic algorithms or neural networks.	Flexible, adapts to changing conditions; computationally expensive.
Multi-Level Hyper-Heuristics	Uses high-level strategies to select and combine lower-level hyper-heuristics.	Handles complex problems; increased complexity and computational overhead.
Parallel Hyper-Heuristics	Executes heuristics in parallel across multiple processors.	Reduces computational time; requires specialized infrastructure.
Online Learning Hyper-Heuristics	Adapts heuristic selection using reinforcement learning or other ML techniques.	Adaptable to dynamic problems; requires significant computational resources.
Conclusion
Hyper-heuristic algorithms represent a powerful approach to solving complex optimization problems by automating the selection, generation, and adaptation of heuristics. Their ability to generalize across different problem domains and adapt to changing conditions makes them a valuable tool for both researchers and practitioners. While they offer several advantages, such as improved generality and adaptability, they also present challenges, such as increased computational overhead and dependence on the quality of low-level heuristics. As research in this field continues to evolve, hyper-heuristics are expected to play an increasingly important role in addressing real-world optimization challenges.


# 3. Method





# 4. Results




# 5. Discussion


Limitations:
- Reduced dimensionalities of search space (prompt optimisation strategies, test time scaling strategies, model decoding parameters, selection of language models)
- Assumptions made on the associativity and composability of the heuristic components.
- Initial break up of complex tasks into simpler subtasks
- Adoption of agent framework to this search problem (i.e. master agent to search solution for the )



# 6. Conclusion





# Appendix

## Directed Acyclic Graph,  Hyper Heuristic Optimisation and Reinforcement Learning
Relationship Between Directed Acyclic Graphs (DAGs) and Hyper-Heuristic Optimization

There exists a significant relationship between Directed Acyclic Graphs (DAGs) and Hyper-Heuristic Optimization in the context of problem-solving, algorithm selection, and heuristic search. The connection primarily lies in the representation of solution spaces, the flow of heuristic choices, and the structural organization of optimization strategies.

1. DAGs as a Representation of Hyper-Heuristic Decision Processes
	•	A Directed Acyclic Graph (DAG) is a graph structure where nodes represent states, solutions, or decisions, and edges represent dependencies or transitions between these states.
	•	In Hyper-Heuristic Optimization, the goal is to select, generate, or combine heuristics dynamically to solve complex optimization problems.
	•	DAGs can be used to model the flow of decision-making in hyper-heuristics, where:
	•	Nodes represent heuristic operators, heuristic components, or intermediate solutions.
	•	Edges indicate possible transitions from one heuristic decision to another, ensuring the process moves forward without cycles.

Example:
	•	A hyper-heuristic framework can be structured as a DAG where:
	•	Each node represents a meta-decision (e.g., selecting a mutation operator, tuning a parameter, or choosing a local search technique).
	•	Directed edges represent valid transitions between heuristics in the optimization pipeline.
	•	The acyclic nature ensures that the process does not fall into an infinite loop and progresses toward an optimal or near-optimal solution.

2. DAGs in Adaptive Hyper-Heuristic Frameworks
	•	In adaptive hyper-heuristics, the search strategy learns from past decisions and adapts accordingly.
	•	DAG-based models are used in reinforcement learning-driven hyper-heuristics, where:
	•	Each path in the DAG represents a sequence of heuristic applications.
	•	The best-performing paths can be exploited to guide future heuristic choices.

Example:
	•	In a Genetic Algorithm-based Hyper-Heuristic, a DAG can be used to model the hierarchy of crossover, mutation, and selection strategies.
	•	The system learns which heuristic combinations perform well and refines the DAG structure dynamically.

3. DAGs in Graph-Based Hyper-Heuristics
	•	Some hyper-heuristic algorithms directly use graph structures where:
	•	Candidate solutions are nodes in a DAG.
	•	Edges represent feasible transformations (e.g., heuristic operations applied to solutions).
	•	The topological sorting of the DAG helps in defining efficient search paths in the solution space.

Example:
	•	In automated machine learning (AutoML) and Neural Architecture Search (NAS):
	•	The search space of network architectures can be structured as a DAG.
	•	A hyper-heuristic algorithm navigates through this DAG to optimize neural network architectures.

4. DAGs in Metaheuristic Hybridization via Hyper-Heuristics
	•	Hybrid metaheuristics often employ DAG structures to combine multiple optimization strategies effectively.
	•	Hyper-heuristics leverage DAGs to determine when and how to switch between different metaheuristic strategies.

Example:
	•	A DAG-based hyper-heuristic might decide when to switch between simulated annealing, genetic algorithms, and particle swarm optimization, ensuring smooth transitions without redundant cycles.

Conclusion
	•	DAGs provide a structured framework for representing hyper-heuristic search processes.
	•	They ensure efficient transitions between heuristic choices while preventing cycles.
	•	Many hyper-heuristic frameworks, especially adaptive and learning-based ones, use DAGs to model decision sequences.
	•	DAGs help organize, guide, and optimize heuristic selection strategies in large and complex problem spaces.

This connection is particularly important in automated algorithm selection, neural architecture search, reinforcement learning-based hyper-heuristics, and hybrid metaheuristic optimization frameworks.

